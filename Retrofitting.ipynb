{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(46)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps:\n",
    "\n",
    "Generate random word vectors\n",
    "\n",
    "Generate a random lexicon between them\n",
    "\n",
    "Use the lexicon to update the original word vectors such that the new word vectors are close to the original word vectors and neighbours in the lexicon.\n",
    "\n",
    "alpha is the parameter which specifies the closeness to the original vector\n",
    "\n",
    "beta is the parameter which specifies the closeness to the neighbours in the lexicon\n",
    "\n",
    "papar used an euclidian distance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random word vectors\n",
    "word_vectors = np.random.randn(50,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defined words\n",
    "words = [\"word_\" + str(x) for x in range(50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words2index = {v:k for k, v in enumerate(words)}\n",
    "index2words = {k:v for k, v in enumerate(words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking a sample of 5 words to create a lexicon\n",
    "sampled_words_for_lexicon = np.random.randint(0,10,3)\n",
    "sampled_words_for_lexicon_2 = np.random.randint(13,45,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 1, 9])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_words_for_lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29, 16])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_words_for_lexicon_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random lexicon\n",
    "lexicon = {}\n",
    "for each_word in sampled_words_for_lexicon:\n",
    "    # each word is connected all the other words in this sample\n",
    "    to_connect = list(set(sampled_words_for_lexicon) - set([each_word]))\n",
    "    lexicon[\"word_\" + str(each_word)] = [\"word_\" + str(x) for x in to_connect]\n",
    "    \n",
    "for each_word in sampled_words_for_lexicon_2:\n",
    "    # each word is connected all the other words in this sample\n",
    "    to_connect = list(set(sampled_words_for_lexicon_2) - set([each_word]))\n",
    "    lexicon[\"word_\" + str(each_word)] = [\"word_\" + str(x) for x in to_connect]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'word_8': ['word_1', 'word_9'],\n",
       " 'word_1': ['word_8', 'word_9'],\n",
       " 'word_9': ['word_8', 'word_1'],\n",
       " 'word_29': ['word_16'],\n",
       " 'word_16': ['word_29']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting lexicon into indices\n",
    "lexicon_i = {}\n",
    "for k, v in lexicon.items():\n",
    "    lexicon_i[words2index[k]] = [words2index[x] for x in v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{8: [1, 9], 1: [8, 9], 9: [8, 1], 29: [16], 16: [29]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using lexicon to update word vectors\n",
    "def retrofit(word_vectors, lexicon_i, n_iters= 10, alpha=0.95, beta=0.05):\n",
    "    new_word_vectors = word_vectors.copy()\n",
    "    words_in_lexicon = lexicon_i.keys()\n",
    "    # n_iters is the num of steps of iterative update\n",
    "    # alpha is the closeness to original\n",
    "    # beta is the closeness to neighbours in the lexicon\n",
    "    for each_iter in range(n_iters):\n",
    "        # update the words only in the lexicon\n",
    "        for each_word in words_in_lexicon:\n",
    "            # update\n",
    "            len_conn = len(lexicon_i[each_word])\n",
    "            if len_conn > 0:\n",
    "                new_word_vectors[each_word,:] = alpha * len_conn * new_word_vectors[each_word,:]\n",
    "                for each_connection in lexicon_i[each_word]:\n",
    "                    new_word_vectors[each_word,:] += beta * new_word_vectors[each_connection,:]\n",
    "                # normalization\n",
    "                new_word_vectors[each_word,:] = (new_word_vectors[each_word,:]) / len_conn * (alpha + beta)\n",
    "    return new_word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{8: [1, 9], 1: [8, 9], 9: [8, 1], 29: [16], 16: [29]}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_word_vectors = retrofit(word_vectors, lexicon_i,  n_iters = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old distance 25.301451046423388\n",
      "new distance 11.724400082997878\n"
     ]
    }
   ],
   "source": [
    "#  did it work\n",
    "# 8, 1, 9 should be closer\n",
    "# checking distance between old vectors and comparing with distances between new vectors \n",
    "dist = np.linalg.norm(word_vectors[8,:] - word_vectors[1,:])\n",
    "print(\"old distance {}\".format(dist))\n",
    "\n",
    "dist = np.linalg.norm(new_word_vectors[8,:] - new_word_vectors[1,:])\n",
    "print(\"new distance {}\".format(dist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old distance 23.402891658840684\n",
      "new distance 8.389607203346678\n"
     ]
    }
   ],
   "source": [
    "#  did it work\n",
    "# 16 and 29 should be closer\n",
    "# checking distance between old vectors and comparing with distances between new vectors \n",
    "dist = np.linalg.norm(word_vectors[16,:] - word_vectors[29,:])\n",
    "print(\"old distance {}\".format(dist))\n",
    "\n",
    "dist = np.linalg.norm(new_word_vectors[16,:] - new_word_vectors[29,:])\n",
    "print(\"new distance {}\".format(dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{8: [1, 9], 1: [8, 9], 9: [8, 1], 29: [16], 16: [29]}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking distance between old vector and updated new vector\n",
    "distances = []\n",
    "for each_word, _ in lexicon_i.items():\n",
    "    distances.append(np.linalg.norm(new_word_vectors[each_word,:] - word_vectors[each_word,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.7739978878082265"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
