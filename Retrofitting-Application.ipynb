{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# got a lexicon from the internet\n",
    "import csv\n",
    "with open(\"framenet.txt\",'r') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [x.strip() for x in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'source'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating lexicon \n",
    "lexicon = {}\n",
    "for each_line in lines:\n",
    "    words = each_line.split(' ')\n",
    "    if len(words) > 1:\n",
    "        lexicon[words[0]] = words[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7855"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300-SLIM.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299567, 300)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = model.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab= list(model.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7501"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# match between lexicon and voacb\n",
    "len(set(vocab).intersection(set(list(lexicon.keys()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "words2index = {v:k for k, v in enumerate(vocab)}\n",
    "index2words = {k:v for k, v in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting lexicon into indices\n",
    "lexicon_i = {}\n",
    "for k, v in lexicon.items():\n",
    "    if k in vocab:\n",
    "        temp = [words2index.get(x,'') for x in v]\n",
    "        temp = [x for x in temp if x]\n",
    "        lexicon_i[words2index[k]] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sprinkle'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2words[30168]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rainfall',\n",
       " 'downpour',\n",
       " 'snow',\n",
       " 'snowfall',\n",
       " 'drizzle',\n",
       " 'sleet',\n",
       " 'shower',\n",
       " 'rain',\n",
       " 'torrential',\n",
       " 'precipitation',\n",
       " 'torrent',\n",
       " 'hail']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon[index2words[30168]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10233,\n",
       " 29030,\n",
       " 2322,\n",
       " 15580,\n",
       " 27278,\n",
       " 27959,\n",
       " 9168,\n",
       " 2209,\n",
       " 74333,\n",
       " 15151,\n",
       " 25468,\n",
       " 12145]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon_i[30168]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using lexicon to update word vectors\n",
    "def retrofit(word_vectors, lexicon_i, n_iters= 10, alpha=0.95, beta=0.05):\n",
    "    new_word_vectors = word_vectors.copy()\n",
    "    words_in_lexicon = lexicon_i.keys()\n",
    "    # n_iters is the num of steps of iterative update\n",
    "    # alpha is the closeness to original\n",
    "    # beta is the closeness to neighbours in the lexicon\n",
    "    for each_iter in range(n_iters):\n",
    "        # update the words only in the lexicon\n",
    "        for each_word in words_in_lexicon:\n",
    "            # update\n",
    "            len_conn = len(lexicon_i[each_word])\n",
    "            if len_conn > 0:\n",
    "                new_word_vectors[each_word,:] = alpha * len_conn * new_word_vectors[each_word,:]\n",
    "                for each_connection in lexicon_i[each_word]:\n",
    "                    new_word_vectors[each_word,:] += beta * new_word_vectors[each_connection,:]\n",
    "                # normalization\n",
    "                new_word_vectors[each_word,:] = (new_word_vectors[each_word,:]) / len_conn * (alpha + beta)\n",
    "    return new_word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_word_vectors = retrofit(word_vectors, lexicon_i,  n_iters = 10, alpha =0.95, beta= 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299567, 300)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_word_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.vectors = new_word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: sprinkle\n",
      "Words connected in lexicon: ['rainfall', 'downpour', 'snow', 'snowfall', 'drizzle', 'sleet', 'shower', 'rain', 'torrential', 'precipitation', 'torrent', 'hail']\n"
     ]
    }
   ],
   "source": [
    "print(\"Word: {}\".format(index2words[30168]))\n",
    "print(\"Words connected in lexicon: {}\".format(lexicon[index2words[30168]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### are the words in lexicon at a lesser distance in retrofit model\n",
    "\n",
    "yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('drizzle', 0.737594485282898),\n",
       " ('sprinkling', 0.7267799973487854),\n",
       " ('sprinkles', 0.6991304159164429),\n",
       " ('sprinkled', 0.6447292566299438),\n",
       " ('rain', 0.618393063545227),\n",
       " ('moistened', 0.6180086731910706),\n",
       " ('drizzled', 0.6157044172286987),\n",
       " ('Sprinkle', 0.6119532585144043),\n",
       " ('moisten', 0.6049048900604248),\n",
       " ('shower', 0.6036059856414795),\n",
       " ('sleet', 0.6020184755325317),\n",
       " ('drench', 0.5991118550300598),\n",
       " ('tablespoon', 0.597425639629364),\n",
       " ('downpour', 0.5962713956832886),\n",
       " ('drizzling', 0.5769487619400024),\n",
       " ('dab', 0.57546067237854),\n",
       " ('Moisten', 0.5751141905784607),\n",
       " ('glaze', 0.5705564022064209),\n",
       " ('precipitation', 0.5693178176879883),\n",
       " ('soak', 0.5669090151786804),\n",
       " ('tbsp', 0.5659164190292358),\n",
       " ('pour', 0.5633883476257324),\n",
       " ('tsp', 0.5618157386779785),\n",
       " ('snow', 0.559573769569397),\n",
       " ('Drizzle', 0.558053731918335),\n",
       " ('spoonful', 0.5555875897407532),\n",
       " ('cupfuls', 0.5552812814712524),\n",
       " ('teaspoon', 0.5501717329025269),\n",
       " ('rainfall', 0.549561083316803),\n",
       " ('hail', 0.5488933324813843)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.most_similar(\"sprinkle\",topn=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### are the original embeddings preserved?\n",
    "\n",
    "yes\n",
    "\n",
    "sprinkling original cosine is 0.73, in the retrofit model the distance is 0.72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sprinkling', 0.7351713180541992),\n",
       " ('sprinkled', 0.6881633400917053),\n",
       " ('Sprinkle', 0.6744049191474915),\n",
       " ('sprinkles', 0.6474019885063171),\n",
       " ('tablespoon', 0.5909141302108765),\n",
       " ('tsp', 0.5867205858230591),\n",
       " ('tbsp', 0.5865833163261414),\n",
       " ('Garnish', 0.5789077281951904),\n",
       " ('Moisten', 0.5742171406745911),\n",
       " ('dollop', 0.573137104511261),\n",
       " ('drizzled', 0.563011646270752),\n",
       " ('tablespoons', 0.5598653554916382),\n",
       " ('Tbsp', 0.5437169075012207),\n",
       " ('spoonful', 0.5397160053253174),\n",
       " ('Drizzle', 0.5386276245117188)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"sprinkle\",topn=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72677994"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.similarity(\"sprinkle\",\"sprinkling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old distance 1.2846770286560059\n",
      "new distance 0.7379277348518372\n"
     ]
    }
   ],
   "source": [
    "#  did it work\n",
    "# checking distance between old vectors and comparing with distances between new vectors \n",
    "dist = np.linalg.norm(word_vectors[30168,:] - word_vectors[10233,:])\n",
    "print(\"old distance {}\".format(dist))\n",
    "\n",
    "dist = np.linalg.norm(new_word_vectors[30168,:] - new_word_vectors[10233,:])\n",
    "print(\"new distance {}\".format(dist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking distance between old vector and updated new vector\n",
    "distances = []\n",
    "for each_word, _ in lexicon_i.items():\n",
    "    distances.append(np.linalg.norm(new_word_vectors[each_word,:] - word_vectors[each_word,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3467867"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
